<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.9" />
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html,
      body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia('(prefers-color-scheme: dark)').matches
      if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
        document.documentElement.classList.toggle('dark', true)
      }
    </script>
    <title>线性模型 | Online notes</title><meta name="description" content="">
    <link rel="preload" href="/online_notesV2/assets/style-D5vwsrtQ.css" as="style"><link rel="stylesheet" href="/online_notesV2/assets/style-D5vwsrtQ.css">
    <link rel="modulepreload" href="/online_notesV2/assets/app-DFklLwn2.js"><link rel="modulepreload" href="/online_notesV2/assets/3_机器学习-1线性模型.html-C2woTet8.js">
    <link rel="prefetch" href="/online_notesV2/assets/index.html-B_ofms2i.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/HR面准备.html-BK8s8tMW.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-DPbrAdIg.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/字节跳动面试.html-C-PaAaLH.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-C-1zT8Qw.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/写题常用python技法.html-BlRSaPPH.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/动态规划.html-DG4iyXtp.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/回溯算法.html-D9_jwHvq.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/图.html-DrYCM1Yj.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/排序.html-L1Q_Zl6P.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/数字或者字符串合成.html-BvNvZhYQ.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/数学.html-Dr0zsDHy.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/概率题.html-BIA_ICCA.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/链表.html-FWrnmbaz.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-DWVDw19-.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/simple_resume_En.html-Da2jpqDv.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/simple_resume_Zh.html-Nx7IBfbJ.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/1_数学基础-损失函数与熵.html-DGGxcJDP.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/1_数学基础-最优化.html-D5oCYe6m.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/1_数学基础-期望方差协方差.html-56RkrfD1.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/2_数据相关-SVD_PCA_LSA.html-DYpgVGJ_.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/2_数据相关-评价指标.html-Dq1Ftk0F.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/2_数据相关-采样.html-0_ukPuSO.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/3_机器学习-2支持向量机.html-D_OWA4DG.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/3_机器学习-集成学习.html-Cm09Nslg.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-qbYWCUYX.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/attention.html-B2XYC_za.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/手撕机器学习代码系列.html-CzwSgy2c.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/推荐系统.html-BMYFEpJC.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/神经网络--Normalization Layers.html-BRkDdOPo.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/神经网络--RNN_LSTM_GRU.html-t8K2QoUo.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/神经网络--优化器.html-BYSp3dHv.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/神经网络--初始化.html-Bp4yTvf4.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/神经网络--卷积神经网络.html-BjgT7g56.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/面试概率题.html-BKqKRW3U.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/LLM.html-DRzcTUP6.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-Csmp7D_E.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/基础 -- word embedding.html-B2f3m1Lx.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/基础 -- 词模型.html-bGzxFcgU.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/模型 -- Transformer.html-DBWY2rM8.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-CE0lTX6v.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/fm系列论文.html-DCPhke4w.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/uplift.html-S-Tc8o3u.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/召回.html-0Vo4Rtwf.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/多任务模型.html-6JQc91QZ.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/常用评估指标.html-DqXhDGQu.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/序列处理相关论文.html-DFt-7v-Y.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/时长建模.html-Bvr0g7sa.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/消偏.html-n3iN1nlp.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/转化延迟.html-Q4t1_Kx4.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-C95eu_ab.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/哈工大DB-第1讲初步认识数据库.html-TAvtTDYS.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-fG8xqCok.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/lec1.html-Dn6tUGxh.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-Dv8UPuZv.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/lec1.html-D2TbJBBe.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-D4-5NUlL.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/lec1.html-DiJKWFOd.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/lec2.html-BDynTW1W.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/lec3.html-Cp5oSZdF.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/10.补充-类模板函数模板和其他.html-CLID8m4C.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/11.组合与继承.html-BYLWeO93.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/2.头文件.html-D5T48Stk.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/3.构造函数.html-B984ecog.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/4.参数传递与返回值.html-zFxdK0b4.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/5.操作符重载与临时对象.html-DLFNBZjv.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-SkHE0PWr.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/堆栈.html-Oc_2dRXZ.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/类的成员变量.html-BuYGcBkG.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/虚函数与多态.html-DQGjawzF.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-VfU0UJYg.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/git操作.html-d0PEp1MZ.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-m41GgfvC.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/python输入输出.html-C9njZmWi.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/python面试常考.html-CPT4bmUv.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/常用的数据结构和方法.html-Dq6eZ-au.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/404.html-Dp-iF5Ng.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/online_notesV2/"><img class="logo" src="/online_notesV2/icon.gif" alt="Online notes"><span class="site-name can-hide" aria-hidden="true">Online notes</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide" aria-label="site navigation"><!--[--><div class="navbar-item"><a class="route-link" href="/online_notesV2/Algorithm/" aria-label="算法"><!--[--><!--[--><!--]--> 算法 <!--[--><!--]--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Notes"><span class="title">Notes</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Notes"><span class="title">Notes</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_introRL/" aria-label="introRL"><!--[--><!--[--><!--]--> introRL <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_LeeRL/" aria-label="LeeRL"><!--[--><!--[--><!--]--> LeeRL <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_DRL_CS285/" aria-label="DRL_CS285"><!--[--><!--[--><!--]--> DRL_CS285 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="AI"><span class="title">AI</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="AI"><span class="title">AI</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link route-link-active" href="/online_notesV2/AI/Basic/" aria-label="基础"><!--[--><!--[--><!--]--> 基础 <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/AI/NLP/" aria-label="NLP"><!--[--><!--[--><!--]--> NLP <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/AI/RecSys/" aria-label="推荐系统"><!--[--><!--[--><!--]--> 推荐系统 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="编程"><span class="title">编程</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="编程"><span class="title">编程</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/python/" aria-label="python"><!--[--><!--[--><!--]--> python <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/cpp/" aria-label="c++"><!--[--><!--[--><!--]--> c++ <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/others/" aria-label="杂七杂八"><!--[--><!--[--><!--]--> 杂七杂八 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><button class="toggle-color-mode-button" title="toggle color mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items" aria-label="site navigation"><!--[--><div class="navbar-item"><a class="route-link" href="/online_notesV2/Algorithm/" aria-label="算法"><!--[--><!--[--><!--]--> 算法 <!--[--><!--]--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Notes"><span class="title">Notes</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Notes"><span class="title">Notes</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_introRL/" aria-label="introRL"><!--[--><!--[--><!--]--> introRL <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_LeeRL/" aria-label="LeeRL"><!--[--><!--[--><!--]--> LeeRL <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_DRL_CS285/" aria-label="DRL_CS285"><!--[--><!--[--><!--]--> DRL_CS285 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="AI"><span class="title">AI</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="AI"><span class="title">AI</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link route-link-active" href="/online_notesV2/AI/Basic/" aria-label="基础"><!--[--><!--[--><!--]--> 基础 <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/AI/NLP/" aria-label="NLP"><!--[--><!--[--><!--]--> NLP <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/AI/RecSys/" aria-label="推荐系统"><!--[--><!--[--><!--]--> 推荐系统 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="编程"><span class="title">编程</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="编程"><span class="title">编程</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/python/" aria-label="python"><!--[--><!--[--><!--]--> python <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/cpp/" aria-label="c++"><!--[--><!--[--><!--]--> c++ <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/others/" aria-label="杂七杂八"><!--[--><!--[--><!--]--> 杂七杂八 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading active">AI基础 <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/1_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E7%86%B5.html" aria-label="熵和损失函数和激活函数"><!--[--><!--[--><!--]--> 熵和损失函数和激活函数 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/1_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E6%9C%80%E4%BC%98%E5%8C%96.html" aria-label="数学基础-最优化"><!--[--><!--[--><!--]--> 数学基础-最优化 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/1_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E6%9C%9F%E6%9C%9B%E6%96%B9%E5%B7%AE%E5%8D%8F%E6%96%B9%E5%B7%AE.html" aria-label="数学基础-期望方差协方差"><!--[--><!--[--><!--]--> 数学基础-期望方差协方差 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/2_%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3-SVD_PCA_LSA.html" aria-label="SVD_PCA_LSA"><!--[--><!--[--><!--]--> SVD_PCA_LSA <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/2_%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3-%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87.html" aria-label="评价指标"><!--[--><!--[--><!--]--> 评价指标 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/2_%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3-%E9%87%87%E6%A0%B7.html" aria-label="采样直观思想"><!--[--><!--[--><!--]--> 采样直观思想 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link route-link-active sidebar-item active" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html" aria-label="线性模型"><!--[--><!--[--><!--]--> 线性模型 <!--[--><!--]--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="#_0-参考资料" aria-label="0.参考资料："><!--[--><!--[--><!--]--> 0.参考资料： <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_00-补充数学知识" aria-label="00 补充数学知识："><!--[--><!--[--><!--]--> 00 补充数学知识： <!--[--><!--]--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="#_1-什么是方差的无偏估计" aria-label="1. 什么是方差的无偏估计"><!--[--><!--[--><!--]--> 1. 什么是方差的无偏估计 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_2-先验后验" aria-label="2. 先验后验"><!--[--><!--[--><!--]--> 2. 先验后验 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_3-概率分布" aria-label="3. 概率分布"><!--[--><!--[--><!--]--> 3. 概率分布 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_4-为什么要最大化似然函数" aria-label="4. 为什么要最大化似然函数"><!--[--><!--[--><!--]--> 4. 为什么要最大化似然函数 <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><li><a class="route-link sidebar-item" href="#_1-线性回归" aria-label="1. 线性回归"><!--[--><!--[--><!--]--> 1. 线性回归 <!--[--><!--]--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="#_1-1-视角1-直接选择均方误差为损失函数-最小化损失-最小二乘法" aria-label="1.1 视角1：直接选择均方误差为损失函数，最小化损失(最小二乘法)"><!--[--><!--[--><!--]--> 1.1 视角1：直接选择均方误差为损失函数，最小化损失(最小二乘法) <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_1-2-视角2-假定模型输出含有高斯白噪声-高斯函数分布为似然函数-极大似然估计" aria-label="1.2 视角2：假定模型输出含有高斯白噪声，高斯函数分布为似然函数，极大似然估计"><!--[--><!--[--><!--]--> 1.2 视角2：假定模型输出含有高斯白噪声，高斯函数分布为似然函数，极大似然估计 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_1-3-正则化其实是对模型参数的最大后验" aria-label="1.3 正则化其实是对模型参数的最大后验"><!--[--><!--[--><!--]--> 1.3 正则化其实是对模型参数的最大后验 <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><li><a class="route-link sidebar-item" href="#_2-逻辑回归-对数几率函数为输出-极大似然法" aria-label="2. 逻辑回归--对数几率函数为输出，极大似然法"><!--[--><!--[--><!--]--> 2. 逻辑回归--对数几率函数为输出，极大似然法 <!--[--><!--]--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="#_2-1-模型的输出" aria-label="2.1 模型的输出"><!--[--><!--[--><!--]--> 2.1 模型的输出 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_2-2-模型的损失函数及梯度" aria-label="2.2 模型的损失函数及梯度"><!--[--><!--[--><!--]--> 2.2 模型的损失函数及梯度 <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><li><a class="route-link sidebar-item" href="#_3-逻辑回归、线性回归与极大似然法" aria-label="3. 逻辑回归、线性回归与极大似然法"><!--[--><!--[--><!--]--> 3. 逻辑回归、线性回归与极大似然法 <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-2%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.html" aria-label="支持向量机"><!--[--><!--[--><!--]--> 支持向量机 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.html" aria-label="集成学习"><!--[--><!--[--><!--]--> 集成学习 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link route-link-active sidebar-item" href="/online_notesV2/AI/Basic/" aria-label="机器学习/深度学习--基础"><!--[--><!--[--><!--]--> 机器学习/深度学习--基础 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/attention.html" aria-label="Attention"><!--[--><!--[--><!--]--> Attention <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E6%89%8B%E6%92%95%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%E7%B3%BB%E5%88%97.html" aria-label="手撕机器学习代码"><!--[--><!--[--><!--]--> 手撕机器学习代码 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html" aria-label="推荐系统"><!--[--><!--[--><!--]--> 推荐系统 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--Normalization%20Layers.html" aria-label="基础神经网络--Layer Norm"><!--[--><!--[--><!--]--> 基础神经网络--Layer Norm <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html" aria-label="神经网络--RNN|LSTM|GRU"><!--[--><!--[--><!--]--> 神经网络--RNN|LSTM|GRU <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E4%BC%98%E5%8C%96%E5%99%A8.html" aria-label="基础神经网络--优化器"><!--[--><!--[--><!--]--> 基础神经网络--优化器 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E5%88%9D%E5%A7%8B%E5%8C%96.html" aria-label="基础神经网络--优化器"><!--[--><!--[--><!--]--> 基础神经网络--优化器 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html" aria-label="基础神经网络--卷积神经网络"><!--[--><!--[--><!--]--> 基础神经网络--卷积神经网络 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E9%9D%A2%E8%AF%95%E6%A6%82%E7%8E%87%E9%A2%98.html" aria-label="面试概率题"><!--[--><!--[--><!--]--> 面试概率题 <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><h1 id="线性模型" tabindex="-1"><a class="header-anchor" href="#线性模型"><span>线性模型</span></a></h1><nav class="table-of-contents"><ul><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_0-参考资料" class="router-link-active router-link-exact-active">0.参考资料：</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_00-补充数学知识" class="router-link-active router-link-exact-active">00 补充数学知识：</a><ul><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-什么是方差的无偏估计" class="router-link-active router-link-exact-active">1. 什么是方差的无偏估计</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-先验后验" class="router-link-active router-link-exact-active">2. 先验后验</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_3-概率分布" class="router-link-active router-link-exact-active">3. 概率分布</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_4-为什么要最大化似然函数" class="router-link-active router-link-exact-active">4. 为什么要最大化似然函数</a></li></ul></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-线性回归" class="router-link-active router-link-exact-active">1. 线性回归</a><ul><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-1-视角1-直接选择均方误差为损失函数-最小化损失-最小二乘法" class="router-link-active router-link-exact-active">1.1 视角1：直接选择均方误差为损失函数，最小化损失(最小二乘法)</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-2-视角2-假定模型输出含有高斯白噪声-高斯函数分布为似然函数-极大似然估计" class="router-link-active router-link-exact-active">1.2 视角2：假定模型输出含有高斯白噪声，高斯函数分布为似然函数，极大似然估计</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-3-正则化其实是对模型参数的最大后验" class="router-link-active router-link-exact-active">1.3 正则化其实是对模型参数的最大后验</a></li></ul></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-逻辑回归-对数几率函数为输出-极大似然法" class="router-link-active router-link-exact-active">2. 逻辑回归--对数几率函数为输出，极大似然法</a><ul><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-1-模型的输出" class="router-link-active router-link-exact-active">2.1 模型的输出</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-2-模型的损失函数及梯度" class="router-link-active router-link-exact-active">2.2 模型的损失函数及梯度</a></li></ul></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_3-逻辑回归、线性回归与极大似然法" class="router-link-active router-link-exact-active">3. 逻辑回归、线性回归与极大似然法</a></li></ul></nav><h2 id="_0-参考资料" tabindex="-1"><a class="header-anchor" href="#_0-参考资料"><span>0.参考资料：</span></a></h2><ul><li></li><li>ROC可以更聚焦于模型本身，降低测试集带来的干扰</li><li>生成式模型和判别式模型的区别https://www.zhihu.com/question/20446337/answer/1661760071</li></ul><hr><h2 id="_00-补充数学知识" tabindex="-1"><a class="header-anchor" href="#_00-补充数学知识"><span>00 补充数学知识：</span></a></h2><h3 id="_1-什么是方差的无偏估计" tabindex="-1"><a class="header-anchor" href="#_1-什么是方差的无偏估计"><span>1. 什么是方差的无偏估计</span></a></h3><p>参考：</p><ul><li><a href="https://www.zhihu.com/question/20099757/answer/26586088" target="_blank" rel="noopener noreferrer">为什么样本方差（sample variance）的分母是 n-1<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li></li></ul><h4 id="随机变量期望已知时-计算方差" tabindex="-1"><a class="header-anchor" href="#随机变量期望已知时-计算方差"><span>随机变量期望已知时，计算方差</span></a></h4><p>TBD 需要补充中心极限定理</p><img src="/online_notesV2/assets/image-20220628201816396-LKZp5jrN.png" alt="image-20220628201816396" style="zoom:67%;"><h4 id="随机变量期望未知时-方差的有偏估计" tabindex="-1"><a class="header-anchor" href="#随机变量期望未知时-方差的有偏估计"><span>随机变量期望未知时，方差的有偏估计</span></a></h4><img src="/online_notesV2/assets/image-20220628201940536-zUxXigis.png" alt="image-20220628201940536" style="zoom:67%;"><img src="/online_notesV2/assets/image-20220628202019376-Dofxwgps.png" alt="image-20220628202019376" style="zoom:80%;"><h4 id="方差无偏估计" tabindex="-1"><a class="header-anchor" href="#方差无偏估计"><span>方差无偏估计</span></a></h4><p><a href="https://www.zhihu.com/question/20099757/answer/312670291" target="_blank" rel="noopener noreferrer">参考为什么样本方差（sample variance）的分母是 n-1？ - 马同学的回答 - 知乎<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><img src="/online_notesV2/assets/-16564189436151-mo136Xr0.svg" alt="[公式]" style="zoom:67%;"><img src="/online_notesV2/assets/image-20220628202430436-0OHDsnoD.png" alt="image-20220628202430436" style="zoom:47%;"><h3 id="_2-先验后验" tabindex="-1"><a class="header-anchor" href="#_2-先验后验"><span>2. 先验后验</span></a></h3><img src="/online_notesV2/assets/image-20220628204135615-QuQuNsDy.png" alt="image-20220628204135615" style="zoom:50%;"><h3 id="_3-概率分布" tabindex="-1"><a class="header-anchor" href="#_3-概率分布"><span>3. 概率分布</span></a></h3><img src="/online_notesV2/assets/image-20220628204859364-BwxX_Eg1.png" alt="image-20220628204859364" style="zoom:67%;"><h3 id="_4-为什么要最大化似然函数" tabindex="-1"><a class="header-anchor" href="#_4-为什么要最大化似然函数"><span>4. 为什么要最大化似然函数</span></a></h3><ul><li>极大似然估计就是构造一个似然函数，这个似然函数就是样本（所观测到的事件）发生的概率，我们需要做的就是使这个样本发生的概率最大，也就是对未知参数求导，使似然函数取极值。因为只有这样时，样本发生的概率最大。</li><li>线性回归的似然函数是高斯函数。均值为线性模型的输出，方差为高斯白噪声的方差。</li><li>逻辑回归的</li></ul><hr><h2 id="_1-线性回归" tabindex="-1"><a class="header-anchor" href="#_1-线性回归"><span>1. 线性回归</span></a></h2><h3 id="_1-1-视角1-直接选择均方误差为损失函数-最小化损失-最小二乘法" tabindex="-1"><a class="header-anchor" href="#_1-1-视角1-直接选择均方误差为损失函数-最小化损失-最小二乘法"><span>1.1 视角1：直接选择均方误差为损失函数，最小化损失(最小二乘法)</span></a></h3><img src="/online_notesV2/assets/image-20220628204233396-CX05W3-5.png" alt="image-20220628204233396" style="zoom:50%;"><img src="/online_notesV2/assets/image-20220628204256965-BxHeUsdo.png" alt="image-20220628204256965" style="zoom:50%;"><h3 id="_1-2-视角2-假定模型输出含有高斯白噪声-高斯函数分布为似然函数-极大似然估计" tabindex="-1"><a class="header-anchor" href="#_1-2-视角2-假定模型输出含有高斯白噪声-高斯函数分布为似然函数-极大似然估计"><span>1.2 视角2：假定模型输出含有高斯白噪声，高斯函数分布为似然函数，极大似然估计</span></a></h3><img src="/online_notesV2/assets/image-20220628204342147-DdGuZtHP.png" alt="image-20220628204342147" style="zoom:47%;"><img src="/online_notesV2/assets/image-20220628204424950-DLEwgoE1.png" alt="image-20220628204424950" style="zoom:47%;"><h3 id="_1-3-正则化其实是对模型参数的最大后验" tabindex="-1"><a class="header-anchor" href="#_1-3-正则化其实是对模型参数的最大后验"><span>1.3 正则化其实是对模型参数的最大后验</span></a></h3><ul><li>L1正则化：参数先验是拉普拉斯分布</li><li>L2正则化：参数先验是高斯分布</li></ul><img src="/online_notesV2/assets/image-20220628204803472-DLviy_EA.png" alt="image-20220628204803472" style="zoom:47%;"><h2 id="_2-逻辑回归-对数几率函数为输出-极大似然法" tabindex="-1"><a class="header-anchor" href="#_2-逻辑回归-对数几率函数为输出-极大似然法"><span>2. 逻辑回归--对数几率函数为输出，极大似然法</span></a></h2><p><strong>核心在于，如何从对数几率函数推导出似然函数，再推导出损失函数与导数</strong></p><ul><li>逻辑回归其实是想用线性模型去完成一个分类任务</li><li>是对数几率函数的线性模型</li><li>因此，选择对数几率函数（sigmoid是形似S的函数，对数几率函数是代表）作为模型的输出，就可以起到二分类的作用</li><li>详细的推导见《机器学习》--周志华</li></ul><h3 id="_2-1-模型的输出" tabindex="-1"><a class="header-anchor" href="#_2-1-模型的输出"><span>2.1 模型的输出</span></a></h3><img src="/online_notesV2/assets/image-20220628195415624-BYKFgFqo.png" alt="image-20220628195415624" style="zoom:40%;"><p><strong>把式子中的y视为类别概率的话，我们就可以得出模型的似然函数</strong></p><img src="/online_notesV2/assets/image-20220628195652966-fN1yAuEw.png" alt="image-20220628195652966" style="zoom:50%;"><h3 id="_2-2-模型的损失函数及梯度" tabindex="-1"><a class="header-anchor" href="#_2-2-模型的损失函数及梯度"><span>2.2 模型的损失函数及梯度</span></a></h3><p><strong>使用极大似然法，最大化模型的对数似然</strong></p><img src="/online_notesV2/assets/image-20220628195851091-BxA3kNGM.png" alt="image-20220628195851091" style="zoom:47%;"><p>而后求出导数就行了</p><img src="/online_notesV2/assets/image-20220628195928191-CcE91GJ0.png" alt="image-20220628195928191" style="zoom:67%;"><h2 id="_3-逻辑回归、线性回归与极大似然法" tabindex="-1"><a class="header-anchor" href="#_3-逻辑回归、线性回归与极大似然法"><span>3. 逻辑回归、线性回归与极大似然法</span></a></h2><img src="/online_notesV2/assets/image-20230711093845604-CM0FIU9d.png" alt="image-20230711093845604" style="zoom:40%;"></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: henryhuanghenry@outlook.com">henryhuanghenry</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link prev" href="/online_notesV2/AI/Basic/2_%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3-%E9%87%87%E6%A0%B7.html" aria-label="采样直观思想"><!--[--><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span>采样直观思想</span></div><!--]--></a><a class="route-link next" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-2%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.html" aria-label="支持向量机"><!--[--><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span>支持向量机</span></div><!--]--></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/online_notesV2/assets/app-DFklLwn2.js" defer></script>
  </body>
</html>
