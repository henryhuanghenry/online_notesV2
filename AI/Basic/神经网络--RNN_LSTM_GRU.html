<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.9" />
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html,
      body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia('(prefers-color-scheme: dark)').matches
      if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
        document.documentElement.classList.toggle('dark', true)
      }
    </script>
    <title>神经网络--RNN|LSTM|GRU | Online notes</title><meta name="description" content="">
    <link rel="preload" href="/online_notesV2/assets/style-D5vwsrtQ.css" as="style"><link rel="stylesheet" href="/online_notesV2/assets/style-D5vwsrtQ.css">
    <link rel="modulepreload" href="/online_notesV2/assets/app-DFklLwn2.js"><link rel="modulepreload" href="/online_notesV2/assets/神经网络--RNN_LSTM_GRU.html-t8K2QoUo.js">
    <link rel="prefetch" href="/online_notesV2/assets/index.html-B_ofms2i.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/HR面准备.html-BK8s8tMW.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-DPbrAdIg.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/字节跳动面试.html-C-PaAaLH.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-C-1zT8Qw.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/写题常用python技法.html-BlRSaPPH.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/动态规划.html-DG4iyXtp.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/回溯算法.html-D9_jwHvq.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/图.html-DrYCM1Yj.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/排序.html-L1Q_Zl6P.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/数字或者字符串合成.html-BvNvZhYQ.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/数学.html-Dr0zsDHy.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/概率题.html-BIA_ICCA.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/链表.html-FWrnmbaz.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-DWVDw19-.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/simple_resume_En.html-Da2jpqDv.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/simple_resume_Zh.html-Nx7IBfbJ.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/1_数学基础-损失函数与熵.html-DGGxcJDP.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/1_数学基础-最优化.html-D5oCYe6m.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/1_数学基础-期望方差协方差.html-56RkrfD1.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/2_数据相关-SVD_PCA_LSA.html-DYpgVGJ_.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/2_数据相关-评价指标.html-Dq1Ftk0F.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/2_数据相关-采样.html-0_ukPuSO.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/3_机器学习-1线性模型.html-C2woTet8.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/3_机器学习-2支持向量机.html-D_OWA4DG.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/3_机器学习-集成学习.html-Cm09Nslg.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-qbYWCUYX.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/attention.html-B2XYC_za.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/手撕机器学习代码系列.html-CzwSgy2c.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/推荐系统.html-BMYFEpJC.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/神经网络--Normalization Layers.html-BRkDdOPo.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/神经网络--优化器.html-BYSp3dHv.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/神经网络--初始化.html-Bp4yTvf4.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/神经网络--卷积神经网络.html-BjgT7g56.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/面试概率题.html-BKqKRW3U.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/LLM.html-DRzcTUP6.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-Csmp7D_E.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/基础 -- word embedding.html-B2f3m1Lx.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/基础 -- 词模型.html-bGzxFcgU.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/模型 -- Transformer.html-DBWY2rM8.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-CE0lTX6v.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/fm系列论文.html-DCPhke4w.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/uplift.html-S-Tc8o3u.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/召回.html-0Vo4Rtwf.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/多任务模型.html-6JQc91QZ.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/常用评估指标.html-DqXhDGQu.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/序列处理相关论文.html-DFt-7v-Y.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/时长建模.html-Bvr0g7sa.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/消偏.html-n3iN1nlp.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/转化延迟.html-Q4t1_Kx4.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-C95eu_ab.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/哈工大DB-第1讲初步认识数据库.html-TAvtTDYS.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-fG8xqCok.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/lec1.html-Dn6tUGxh.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-Dv8UPuZv.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/lec1.html-D2TbJBBe.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-D4-5NUlL.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/lec1.html-DiJKWFOd.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/lec2.html-BDynTW1W.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/lec3.html-Cp5oSZdF.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/10.补充-类模板函数模板和其他.html-CLID8m4C.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/11.组合与继承.html-BYLWeO93.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/2.头文件.html-D5T48Stk.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/3.构造函数.html-B984ecog.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/4.参数传递与返回值.html-zFxdK0b4.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/5.操作符重载与临时对象.html-DLFNBZjv.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-SkHE0PWr.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/堆栈.html-Oc_2dRXZ.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/类的成员变量.html-BuYGcBkG.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/虚函数与多态.html-DQGjawzF.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-VfU0UJYg.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/git操作.html-d0PEp1MZ.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/index.html-m41GgfvC.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/python输入输出.html-C9njZmWi.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/python面试常考.html-CPT4bmUv.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/常用的数据结构和方法.html-Dq6eZ-au.js" as="script"><link rel="prefetch" href="/online_notesV2/assets/404.html-Dp-iF5Ng.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/online_notesV2/"><img class="logo" src="/online_notesV2/icon.gif" alt="Online notes"><span class="site-name can-hide" aria-hidden="true">Online notes</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide" aria-label="site navigation"><!--[--><div class="navbar-item"><a class="route-link" href="/online_notesV2/Algorithm/" aria-label="算法"><!--[--><!--[--><!--]--> 算法 <!--[--><!--]--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Notes"><span class="title">Notes</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Notes"><span class="title">Notes</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_introRL/" aria-label="introRL"><!--[--><!--[--><!--]--> introRL <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_LeeRL/" aria-label="LeeRL"><!--[--><!--[--><!--]--> LeeRL <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_DRL_CS285/" aria-label="DRL_CS285"><!--[--><!--[--><!--]--> DRL_CS285 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="AI"><span class="title">AI</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="AI"><span class="title">AI</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link route-link-active" href="/online_notesV2/AI/Basic/" aria-label="基础"><!--[--><!--[--><!--]--> 基础 <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/AI/NLP/" aria-label="NLP"><!--[--><!--[--><!--]--> NLP <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/AI/RecSys/" aria-label="推荐系统"><!--[--><!--[--><!--]--> 推荐系统 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="编程"><span class="title">编程</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="编程"><span class="title">编程</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/python/" aria-label="python"><!--[--><!--[--><!--]--> python <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/cpp/" aria-label="c++"><!--[--><!--[--><!--]--> c++ <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/others/" aria-label="杂七杂八"><!--[--><!--[--><!--]--> 杂七杂八 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><button class="toggle-color-mode-button" title="toggle color mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items" aria-label="site navigation"><!--[--><div class="navbar-item"><a class="route-link" href="/online_notesV2/Algorithm/" aria-label="算法"><!--[--><!--[--><!--]--> 算法 <!--[--><!--]--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Notes"><span class="title">Notes</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Notes"><span class="title">Notes</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_introRL/" aria-label="introRL"><!--[--><!--[--><!--]--> introRL <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_LeeRL/" aria-label="LeeRL"><!--[--><!--[--><!--]--> LeeRL <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/CSclass/CSclass_RL_DRL_CS285/" aria-label="DRL_CS285"><!--[--><!--[--><!--]--> DRL_CS285 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="AI"><span class="title">AI</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="AI"><span class="title">AI</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link route-link-active" href="/online_notesV2/AI/Basic/" aria-label="基础"><!--[--><!--[--><!--]--> 基础 <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/AI/NLP/" aria-label="NLP"><!--[--><!--[--><!--]--> NLP <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/AI/RecSys/" aria-label="推荐系统"><!--[--><!--[--><!--]--> 推荐系统 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="编程"><span class="title">编程</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="编程"><span class="title">编程</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/python/" aria-label="python"><!--[--><!--[--><!--]--> python <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/cpp/" aria-label="c++"><!--[--><!--[--><!--]--> c++ <!--[--><!--]--><!--]--></a></li><li class="navbar-dropdown-item"><a class="route-link" href="/online_notesV2/Programming/others/" aria-label="杂七杂八"><!--[--><!--[--><!--]--> 杂七杂八 <!--[--><!--]--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading active">AI基础 <!----></p><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/1_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E7%86%B5.html" aria-label="熵和损失函数和激活函数"><!--[--><!--[--><!--]--> 熵和损失函数和激活函数 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/1_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E6%9C%80%E4%BC%98%E5%8C%96.html" aria-label="数学基础-最优化"><!--[--><!--[--><!--]--> 数学基础-最优化 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/1_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80-%E6%9C%9F%E6%9C%9B%E6%96%B9%E5%B7%AE%E5%8D%8F%E6%96%B9%E5%B7%AE.html" aria-label="数学基础-期望方差协方差"><!--[--><!--[--><!--]--> 数学基础-期望方差协方差 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/2_%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3-SVD_PCA_LSA.html" aria-label="SVD_PCA_LSA"><!--[--><!--[--><!--]--> SVD_PCA_LSA <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/2_%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3-%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87.html" aria-label="评价指标"><!--[--><!--[--><!--]--> 评价指标 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/2_%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3-%E9%87%87%E6%A0%B7.html" aria-label="采样直观思想"><!--[--><!--[--><!--]--> 采样直观思想 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-1%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html" aria-label="线性模型"><!--[--><!--[--><!--]--> 线性模型 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-2%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.html" aria-label="支持向量机"><!--[--><!--[--><!--]--> 支持向量机 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/3_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.html" aria-label="集成学习"><!--[--><!--[--><!--]--> 集成学习 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link route-link-active sidebar-item" href="/online_notesV2/AI/Basic/" aria-label="机器学习/深度学习--基础"><!--[--><!--[--><!--]--> 机器学习/深度学习--基础 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/attention.html" aria-label="Attention"><!--[--><!--[--><!--]--> Attention <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E6%89%8B%E6%92%95%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81%E7%B3%BB%E5%88%97.html" aria-label="手撕机器学习代码"><!--[--><!--[--><!--]--> 手撕机器学习代码 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html" aria-label="推荐系统"><!--[--><!--[--><!--]--> 推荐系统 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--Normalization%20Layers.html" aria-label="基础神经网络--Layer Norm"><!--[--><!--[--><!--]--> 基础神经网络--Layer Norm <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link route-link-active sidebar-item active" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html" aria-label="神经网络--RNN|LSTM|GRU"><!--[--><!--[--><!--]--> 神经网络--RNN|LSTM|GRU <!--[--><!--]--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="#_0-资料网址" aria-label="0.资料网址："><!--[--><!--[--><!--]--> 0.资料网址： <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_1-rnn" aria-label="1. RNN"><!--[--><!--[--><!--]--> 1. RNN <!--[--><!--]--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="#_1-1-rnn的动机" aria-label="1.1 RNN的动机"><!--[--><!--[--><!--]--> 1.1 RNN的动机 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_1-2-rnn的结构和公式" aria-label="1.2 RNN的结构和公式"><!--[--><!--[--><!--]--> 1.2 RNN的结构和公式 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_1-3-rnn的优点、缺点" aria-label="1.3 RNN的优点、缺点"><!--[--><!--[--><!--]--> 1.3 RNN的优点、缺点 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_1-4-rnn中的梯度消失和爆炸" aria-label="1.4 RNN中的梯度消失和爆炸"><!--[--><!--[--><!--]--> 1.4 RNN中的梯度消失和爆炸 <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><li><a class="route-link sidebar-item" href="#_2-lstm" aria-label="2.LSTM"><!--[--><!--[--><!--]--> 2.LSTM <!--[--><!--]--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="#_2-1-lstm的动机" aria-label="2.1 LSTM的动机"><!--[--><!--[--><!--]--> 2.1 LSTM的动机 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_2-2-lstm的结构和公式" aria-label="2.2 LSTM的结构和公式"><!--[--><!--[--><!--]--> 2.2 LSTM的结构和公式 <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><li><a class="route-link sidebar-item" href="#_3-gru" aria-label="3.GRU"><!--[--><!--[--><!--]--> 3.GRU <!--[--><!--]--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="#_3-1-gru的动机" aria-label="3.1 GRU的动机"><!--[--><!--[--><!--]--> 3.1 GRU的动机 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_3-2-gru的结构和公式" aria-label="3.2 GRU的结构和公式"><!--[--><!--[--><!--]--> 3.2 GRU的结构和公式 <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><li><a class="route-link sidebar-item" href="#_4-其他" aria-label="4. 其他"><!--[--><!--[--><!--]--> 4. 其他 <!--[--><!--]--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a class="route-link sidebar-item" href="#_4-0-比较" aria-label="4.0 比较"><!--[--><!--[--><!--]--> 4.0 比较 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_4-1-常使用激活函数" aria-label="4.1 常使用激活函数"><!--[--><!--[--><!--]--> 4.1 常使用激活函数 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_4-2-参数量的计算" aria-label="4.2 参数量的计算"><!--[--><!--[--><!--]--> 4.2 参数量的计算 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_4-3-代码的书写" aria-label="4.3 代码的书写"><!--[--><!--[--><!--]--> 4.3 代码的书写 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="#_4-4-不同的整合方式" aria-label="4.4 不同的整合方式："><!--[--><!--[--><!--]--> 4.4 不同的整合方式： <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><li><a class="route-link sidebar-item" href="#_5-长期依赖以及梯度消失解决" aria-label="5. 长期依赖以及梯度消失解决"><!--[--><!--[--><!--]--> 5. 长期依赖以及梯度消失解决 <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E4%BC%98%E5%8C%96%E5%99%A8.html" aria-label="基础神经网络--优化器"><!--[--><!--[--><!--]--> 基础神经网络--优化器 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E5%88%9D%E5%A7%8B%E5%8C%96.html" aria-label="基础神经网络--优化器"><!--[--><!--[--><!--]--> 基础神经网络--优化器 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html" aria-label="基础神经网络--卷积神经网络"><!--[--><!--[--><!--]--> 基础神经网络--卷积神经网络 <!--[--><!--]--><!--]--></a><!----></li><li><a class="route-link sidebar-item" href="/online_notesV2/AI/Basic/%E9%9D%A2%E8%AF%95%E6%A6%82%E7%8E%87%E9%A2%98.html" aria-label="面试概率题"><!--[--><!--[--><!--]--> 面试概率题 <!--[--><!--]--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><h1 id="神经网络-rnn-lstm-gru" tabindex="-1"><a class="header-anchor" href="#神经网络-rnn-lstm-gru"><span>神经网络--RNN|LSTM|GRU</span></a></h1><nav class="table-of-contents"><ul><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_0-资料网址" class="router-link-active router-link-exact-active">0.资料网址：</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_1-rnn" class="router-link-active router-link-exact-active">1. RNN</a><ul><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_1-1-rnn的动机" class="router-link-active router-link-exact-active">1.1 RNN的动机</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_1-2-rnn的结构和公式" class="router-link-active router-link-exact-active">1.2 RNN的结构和公式</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_1-3-rnn的优点、缺点" class="router-link-active router-link-exact-active">1.3 RNN的优点、缺点</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_1-4-rnn中的梯度消失和爆炸" class="router-link-active router-link-exact-active">1.4 RNN中的梯度消失和爆炸</a></li></ul></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_2-lstm" class="router-link-active router-link-exact-active">2.LSTM</a><ul><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_2-1-lstm的动机" class="router-link-active router-link-exact-active">2.1 LSTM的动机</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_2-2-lstm的结构和公式" class="router-link-active router-link-exact-active">2.2 LSTM的结构和公式</a></li></ul></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_3-gru" class="router-link-active router-link-exact-active">3.GRU</a><ul><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_3-1-gru的动机" class="router-link-active router-link-exact-active">3.1 GRU的动机</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_3-2-gru的结构和公式" class="router-link-active router-link-exact-active">3.2 GRU的结构和公式</a></li></ul></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_4-其他" class="router-link-active router-link-exact-active">4. 其他</a><ul><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_4-0-比较" class="router-link-active router-link-exact-active">4.0 比较</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_4-1-常使用激活函数" class="router-link-active router-link-exact-active">4.1 常使用激活函数</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_4-2-参数量的计算" class="router-link-active router-link-exact-active">4.2 参数量的计算</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_4-3-代码的书写" class="router-link-active router-link-exact-active">4.3 代码的书写</a></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_4-4-不同的整合方式" class="router-link-active router-link-exact-active">4.4 不同的整合方式：</a></li></ul></li><li><a aria-current="page" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN_LSTM_GRU.html#_5-长期依赖以及梯度消失解决" class="router-link-active router-link-exact-active">5. 长期依赖以及梯度消失解决</a></li></ul></nav><h2 id="_0-资料网址" tabindex="-1"><a class="header-anchor" href="#_0-资料网址"><span>0.资料网址：</span></a></h2><ul><li><a href="https://www.jiqizhixin.com/articles/2018-12-18-12" target="_blank" rel="noopener noreferrer">核心机器之心的post<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21" target="_blank" rel="noopener noreferrer">三个神经网络的动图解释<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://paddlepedia.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener noreferrer">飞桨文档<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://www.deeplearningbook.org/" target="_blank" rel="noopener noreferrer">Deep Learning Book<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://www.youtube.com/c/3blue1brown" target="_blank" rel="noopener noreferrer">参考视频--可视化数学非常好的教学<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://www.youtube.com/watch?v=CpD9XlTu3ys" target="_blank" rel="noopener noreferrer">SVD分解的图解视频<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://easyai.tech/ai-definition/lstm/" target="_blank" rel="noopener noreferrer">介绍LSTM<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul><h2 id="_1-rnn" tabindex="-1"><a class="header-anchor" href="#_1-rnn"><span>1. RNN</span></a></h2><h3 id="_1-1-rnn的动机" tabindex="-1"><a class="header-anchor" href="#_1-1-rnn的动机"><span>1.1 RNN的动机</span></a></h3><ul><li>需要处理变长的序列</li><li>要学习到输入的时间的依赖关系</li></ul><h3 id="_1-2-rnn的结构和公式" tabindex="-1"><a class="header-anchor" href="#_1-2-rnn的结构和公式"><span>1.2 RNN的结构和公式</span></a></h3><h4 id="结构" tabindex="-1"><a class="header-anchor" href="#结构"><span>结构</span></a></h4><p><img src="/online_notesV2/assets/architecture-rnn-ltr-DW5rEqrH.png" alt="architecture-rnn-ltr"></p><ul><li>上述结构图参考(https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks#architecture)</li></ul><h4 id="公式" tabindex="-1"><a class="header-anchor" href="#公式"><span>公式</span></a></h4><img src="/online_notesV2/assets/image-20220626143653270-DHsgR_xl.png" alt="image-20220626143653270" style="zoom:25%;"><h4 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h4><ul><li><strong>RNN由输入、隐藏层、输出组成</strong></li><li><strong>输入是逐个输入</strong></li><li><strong>隐藏层--与当前输入、上一个隐藏层 有关</strong>，使用的激活函数为tanh <ul><li>__使用tanh__是因为在级联的时候，如果有一个输入值特别大，而没有tanh归一化[-1,1]的效果的话，连乘下去这个值到最后将会非常大，那么别的比较小的数就没有任何意义了</li></ul></li><li><strong>输出--只与当前隐藏层有关</strong></li></ul><h3 id="_1-3-rnn的优点、缺点" tabindex="-1"><a class="header-anchor" href="#_1-3-rnn的优点、缺点"><span>1.3 RNN的优点、缺点</span></a></h3><table><thead><tr><th>优点:</th><th>缺点：</th></tr></thead><tbody><tr><td>模型大小不随输入长度的增加</td><td>计算缓慢</td></tr><tr><td>可以处理任意长序列</td><td>存在梯度消失和梯度爆炸的问题</td></tr><tr><td>考虑了时间的依赖</td><td></td></tr><tr><td>参数随时间共享</td><td></td></tr></tbody></table><h3 id="_1-4-rnn中的梯度消失和爆炸" tabindex="-1"><a class="header-anchor" href="#_1-4-rnn中的梯度消失和爆炸"><span>1.4 <mark>RNN中的梯度消失和爆炸</mark></span></a></h3><img src="/online_notesV2/assets/image-20220626162631825-By2qavl8.png" alt="image-20220626162631825" style="zoom:33%;"><ul><li><strong>梯度爆炸：学习到的参数矩阵的最大奇异值大于1</strong><ul><li>可以使用梯度裁剪解决(clipping)</li></ul></li><li><strong>梯度消失：学习到的参数矩阵的最大奇异值小于1</strong><ul><li>当最大奇异值小于1的时候，往前传播的时候，随着t越来越大，梯度越来越小，越往前神经网络越不更新，削弱了RNN捕获长距离的能力</li></ul></li></ul><h2 id="_2-lstm" tabindex="-1"><a class="header-anchor" href="#_2-lstm"><span>2.LSTM</span></a></h2><h3 id="_2-1-lstm的动机" tabindex="-1"><a class="header-anchor" href="#_2-1-lstm的动机"><span>2.1 LSTM的动机</span></a></h3><p>__有选择性的输入__以缓解梯度消失的问题</p><h3 id="_2-2-lstm的结构和公式" tabindex="-1"><a class="header-anchor" href="#_2-2-lstm的结构和公式"><span>2.2 LSTM的结构和公式</span></a></h3><h4 id="结构-1" tabindex="-1"><a class="header-anchor" href="#结构-1"><span>结构</span></a></h4><img src="/online_notesV2/assets/1yBXV9o5q7L_CvY7quJt3WQ-BJ8WqO-3.png" alt="img" style="zoom:50%;"><p><img src="/online_notesV2/assets/image-20210511204551220-CazwQ_Pj.png" alt="image-20210511204551220"></p><h4 id="公式-注意-公式中激活函数内的相加不是相加-而是向量拼接" tabindex="-1"><a class="header-anchor" href="#公式-注意-公式中激活函数内的相加不是相加-而是向量拼接"><span>公式--注意，公式中激活函数内的相加不是相加，而是向量拼接</span></a></h4><img src="/online_notesV2/assets/image-20220626172906049-Byyi0RVk.png" alt="image-20220626172906049" style="zoom:80%;"><h4 id="总结-3门3态" tabindex="-1"><a class="header-anchor" href="#总结-3门3态"><span>总结--3门3态</span></a></h4><ul><li><p><strong>门</strong>：</p><ul><li>都与 当前输入 和 上一时刻隐藏层 相关</li><li>都使用sigmoid作为激活函数</li><li>都有可学习参数</li></ul></li><li><p>输入门</p><ul><li>用于 细胞态 中调控 暂态 的输入</li></ul></li><li><p>遗忘门</p><ul><li>用于 细胞态 中调控 上一时刻 细胞态 的输入</li></ul></li><li><p>输出门</p><ul><li>用于从 细胞态 生成 当前时刻的 隐藏层</li></ul></li><li><p><strong>态</strong>：</p></li><li><p>暂态</p><ul><li>与 当前输入 和 上一时刻隐藏层 相关</li><li>使用tanh作为激活函数</li><li>有可学习参数</li></ul></li><li><p>细胞态</p><ul><li>由 暂态 与 上一时刻细胞态 决定</li><li>由 输入门 和 遗忘门 调控输入</li><li>无激活函数</li><li>无可学习参数</li></ul></li><li><p>隐藏层</p><ul><li>直接由 细胞态 经过 tanh 后经由 输出门 调控生成</li><li>使用tanh作为激活函数</li><li>无可学习参数</li></ul></li></ul><h2 id="_3-gru" tabindex="-1"><a class="header-anchor" href="#_3-gru"><span>3.GRU</span></a></h2><h3 id="_3-1-gru的动机" tabindex="-1"><a class="header-anchor" href="#_3-1-gru的动机"><span>3.1 GRU的动机</span></a></h3><h3 id="_3-2-gru的结构和公式" tabindex="-1"><a class="header-anchor" href="#_3-2-gru的结构和公式"><span>3.2 GRU的结构和公式</span></a></h3><h4 id="结构-2" tabindex="-1"><a class="header-anchor" href="#结构-2"><span>结构</span></a></h4><img src="/online_notesV2/assets/1yBXV9o5q7L_CvY7quJt3WQ-BJ8WqO-3.png" alt="img" style="zoom:50%;"><img src="/online_notesV2/assets/gru-CUVXo6Cr.png" alt="gru" style="zoom:50%;"><h4 id="公式-注意-公式中激活函数内的相加不是相加-而是向量拼接-1" tabindex="-1"><a class="header-anchor" href="#公式-注意-公式中激活函数内的相加不是相加-而是向量拼接-1"><span>公式--注意，公式中激活函数内的相加不是相加，而是向量拼接</span></a></h4><img src="/online_notesV2/assets/image-20220626172842386-Dq9pcZ26.png" alt="image-20220626172842386" style="zoom:80%;"><h4 id="总结-2门2态" tabindex="-1"><a class="header-anchor" href="#总结-2门2态"><span>总结--2门2态</span></a></h4><ul><li><p><strong>门</strong>：</p><ul><li>都与当前输入和上一时刻的隐藏层有关，对于 当前输入 和 上一时刻隐藏层 都有可学习参数</li><li>都使用sigmoid激活函数进行逐个元素相乘，相当于门控</li></ul></li><li><p>重置门</p><ul><li>负责在 暂态 中遗忘 上一时刻的隐藏层</li></ul></li><li><p>更新门</p><ul><li>负责在 隐藏层 中调控 暂态 和 上一时刻隐藏层 的比例</li></ul></li><li><p><strong>态</strong>：</p><ul><li>GRU只有暂态和隐藏层</li></ul></li><li><p>暂态</p><ul><li>和RNN的隐藏层类似，只是 参数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4653em;"></span><span class="mord">∗</span></span></span></span>​​​上一时刻隐藏层 需要经 重置门 调控</li><li>tanh为激活函数</li><li>有可学习参数</li></ul></li><li><p>隐藏层</p><ul><li>由 暂态 和 上一时刻隐藏层 经由 更新门 调控输入比例</li><li>无激活函数</li><li>无可学习参数</li></ul></li></ul><h2 id="_4-其他" tabindex="-1"><a class="header-anchor" href="#_4-其他"><span>4. 其他</span></a></h2><h3 id="_4-0-比较" tabindex="-1"><a class="header-anchor" href="#_4-0-比较"><span>4.0 比较</span></a></h3><h4 id="lstm与gru" tabindex="-1"><a class="header-anchor" href="#lstm与gru"><span>LSTM与GRU</span></a></h4><ul><li><p>LSTM能够解决循环神经网络因长期依赖带来的梯度消失和梯度爆炸问题，但是LSTM有三个不同的门，参数较多，训练起来比较困难。</p></li><li><p>GRU只含有两个门控结构，且在超参数全部调优的情况下，二者性能相当，但是GRU结构更为简单，训练样本较少，易实现。</p></li><li><img src="/online_notesV2/assets/image-20220626174043183-B8gPbBt8.png" alt="image-20220626174043183"></li></ul><h3 id="_4-1-常使用激活函数" tabindex="-1"><a class="header-anchor" href="#_4-1-常使用激活函数"><span>4.1 常使用激活函数</span></a></h3><img src="/online_notesV2/assets/image-20220626145349858-DWuCSya3.png" alt="image-20220626145349858" style="zoom:80%;"><h4 id="为何非门控单元的可学习参数-选择tanh而不也是sigmoid" tabindex="-1"><a class="header-anchor" href="#为何非门控单元的可学习参数-选择tanh而不也是sigmoid"><span>为何非门控单元的可学习参数，选择tanh而不也是sigmoid</span></a></h4><ul><li>在输入为0附近，tanh的梯度比sigmoid更大，学习收敛更快</li></ul><h4 id="可否使用relu作为激活函数" tabindex="-1"><a class="header-anchor" href="#可否使用relu作为激活函数"><span>可否使用RELU作为激活函数</span></a></h4><ul><li>使用RELU作为激活函数，则失去了tanh的约束，会引发梯度的消失和爆炸</li><li>如果可学习参数初始化在单位阵附近，则可能可以使用</li></ul><h3 id="_4-2-参数量的计算" tabindex="-1"><a class="header-anchor" href="#_4-2-参数量的计算"><span>4.2 参数量的计算</span></a></h3><p>参考pytorch中的计算：https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html?highlight=lstm#torch.nn.LSTM</p><h3 id="_4-3-代码的书写" tabindex="-1"><a class="header-anchor" href="#_4-3-代码的书写"><span>4.3 代码的书写</span></a></h3><ul><li><a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTM" target="_blank" rel="noopener noreferrer">官方代码<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ul><h3 id="_4-4-不同的整合方式" tabindex="-1"><a class="header-anchor" href="#_4-4-不同的整合方式"><span>4.4 不同的整合方式：</span></a></h3><p>https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks#overview</p><img src="/online_notesV2/assets/image-20220626174913378-BytcAE7M.png" alt="image-20220626174913378" style="zoom:50%;"><h2 id="_5-长期依赖以及梯度消失解决" tabindex="-1"><a class="header-anchor" href="#_5-长期依赖以及梯度消失解决"><span>5. 长期依赖以及梯度消失解决</span></a></h2><p>https://www.cnblogs.com/bonelee/p/10475453.html</p><p>https://zhuanlan.zhihu.com/p/47780305</p><p>https://www.zhihu.com/question/317594964</p><p>LSTM为什么能解决梯度消失：https://zhuanlan.zhihu.com/p/451018380</p></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: henryhuanghenry@outlook.com">henryhuanghenry</span><!----><!--]--><!--]--></span></div></div></footer><nav class="vp-page-nav" aria-label="page navigation"><a class="route-link prev" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--Normalization%20Layers.html" aria-label="基础神经网络--Layer Norm"><!--[--><div class="hint"><span class="arrow left"></span> Prev</div><div class="link"><span>基础神经网络--Layer Norm</span></div><!--]--></a><a class="route-link next" href="/online_notesV2/AI/Basic/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E4%BC%98%E5%8C%96%E5%99%A8.html" aria-label="基础神经网络--优化器"><!--[--><div class="hint">Next <span class="arrow right"></span></div><div class="link"><span>基础神经网络--优化器</span></div><!--]--></a></nav><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/online_notesV2/assets/app-DFklLwn2.js" defer></script>
  </body>
</html>
