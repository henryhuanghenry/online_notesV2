{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c419996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec340585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.version.VERSION)\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fdc7723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainablematrix(shape, name, scope=\"attention\"):\n",
    "    val = tf.Variable(tf.random_uniform_initializer()(shape=shape, dtype=tf.float32), trainable = True, dtype=tf.float32,name=name)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6caec360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'x1:0' shape=(1, 1) dtype=float32, numpy=array([[-0.04878653]], dtype=float32)>\n",
      "<tf.Variable 'x1:0' shape=(1, 1) dtype=float32, numpy=array([[-0.04670376]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "a = get_trainablematrix([1,1], \"x1\", scope=\"attention\")\n",
    "print(a)\n",
    "a = get_trainablematrix([1,1], \"x1\", scope=\"attention\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6edf3f",
   "metadata": {},
   "source": [
    "# attention模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e472bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf1.keras.layers.Layer):\n",
    "    def __init__(self, seqlen, dim, d_q, d_k, d_v):\n",
    "        super(Attention, self).__init__()\n",
    "        self.seqlen = seqlen\n",
    "        self.dim = dim\n",
    "        self.d_q = d_q\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        with tf1.variable_scope(\"attention\", reuse=tf1.AUTO_REUSE):\n",
    "            self.Q = tf1.get_variable(\"Q\", shape=(self.dim, self.d_q), trainable = True, dtype=tf.float32)\n",
    "            self.K = tf1.get_variable(\"K\", shape=(self.dim, self.d_k), trainable = True, dtype=tf.float32)\n",
    "            self.V = tf1.get_variable(\"V\", shape=(self.dim, self.d_v), trainable = True, dtype=tf.float32)\n",
    "        super(Attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, attent_input):\n",
    "        Q_ = tf1.matmul(input_attent, self.Q)\n",
    "        K_ = tf1.matmul(input_attent, self.K)\n",
    "        V_ = tf1.matmul(input_attent, self.V)\n",
    "        print(Q_.shape.as_list())\n",
    "        attent_score = tf1.math.softmax(tf1.matmul(Q_, K_, transpose_b=True)) / tf1.sqrt(tf1.constant(self.d_k, dtype=tf.float32))\n",
    "        attent_out = tf.matmul(attent_score, V_)\n",
    "        print(attent_out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b174942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "length = 6\n",
    "d_wordemb = 3\n",
    "d_q = 10\n",
    "d_k, d_v = d_q, d_q\n",
    "attent = Attention(length, d_wordemb, d_q, d_k, d_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ec5a0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 10]\n",
      "tf.Tensor(\n",
      "[[[ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]]\n",
      "\n",
      " [[ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]]], shape=(2, 6, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_attent = tf1.ones(dtype=tf.float32, shape=(batch_size, length, d_wordemb))\n",
    "attent(input_attent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c53ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 10]\n",
      "tf.Tensor(\n",
      "[[[ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]]\n",
      "\n",
      " [[ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]\n",
      "  [ 0.5191793   0.00296562 -0.30474904 -0.53921634  0.1589164\n",
      "    0.04296602  0.1080056  -0.21033323 -0.10927967  0.28347898]]], shape=(2, 6, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "attent(input_attent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c154d",
   "metadata": {},
   "source": [
    "# 其他草稿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4b1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainablematrix(shape, name, scope=\"attention\"):\n",
    "    val = tf.Variable(tf.random_uniform_initializer()(shape=shape, dtype=tf.float32)), trainable = True, dtype=tf.float32)\n",
    "    return val\n",
    "\n",
    "def self_attention(input_attent, seqlen, d_wordemb, d_q, d_k, d_v):\n",
    "    Q = get_trainablematrix((d_wordemb, d_q), \"Q\")\n",
    "    K = get_trainablematrix((d_wordemb, d_q), \"K\")\n",
    "    V = get_trainablematrix((d_wordemb, d_q), \"V\")\n",
    "#         Q = tf1.get_variable(\"Q\", shape=(d_wordemb, d_q), trainable = True, dtype=tf.float32)\n",
    "#         K = tf1.get_variable(\"K\", shape=(d_wordemb, d_k), trainable = True, dtype=tf.float32)\n",
    "#         V = tf1.get_variable(\"V\", shape=(d_wordemb, d_v), trainable = True, dtype=tf.float32)\n",
    "    for i in range(input_attent.shape[0]):\n",
    "        Q_ = tf1.matmul(input_attent[i], Q)\n",
    "        K_ = tf1.matmul(input_attent[i], K)\n",
    "        V_ = tf1.matmul(input_attent[i], V)\n",
    "        attent_score = tf1.math.softmax((tf1.matmul(Q_, K_ ,transpose_b=True))) / tf1.sqrt(tf1.constant(d_k, dtype=tf.float32))\n",
    "        attent_out = tf1.matmul(attent_score, V_)\n",
    "        return attent_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03fcc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.03541311 -0.06710821 -0.19944526 -0.29378155  0.17137542  0.11188859\n",
      "  -0.01642827 -0.25504765  0.19463758 -0.4111901 ]\n",
      " [-0.03541311 -0.06710821 -0.19944526 -0.29378155  0.17137542  0.11188859\n",
      "  -0.01642827 -0.25504765  0.19463758 -0.4111901 ]\n",
      " [-0.03541311 -0.06710821 -0.19944526 -0.29378155  0.17137542  0.11188859\n",
      "  -0.01642827 -0.25504765  0.19463758 -0.4111901 ]\n",
      " [-0.03541311 -0.06710821 -0.19944526 -0.29378155  0.17137542  0.11188859\n",
      "  -0.01642827 -0.25504765  0.19463758 -0.4111901 ]\n",
      " [-0.03541311 -0.06710821 -0.19944526 -0.29378155  0.17137542  0.11188859\n",
      "  -0.01642827 -0.25504765  0.19463758 -0.4111901 ]\n",
      " [-0.03541311 -0.06710821 -0.19944526 -0.29378155  0.17137542  0.11188859\n",
      "  -0.01642827 -0.25504765  0.19463758 -0.4111901 ]], shape=(6, 10), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(2, 6, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.02162073 -0.32771304 -0.33964375 -0.327148    0.21161705  0.2173236\n",
      "   0.17759325 -0.24361159  0.04366475  0.00855401]\n",
      " [-0.02162073 -0.32771304 -0.33964375 -0.327148    0.21161705  0.2173236\n",
      "   0.17759325 -0.24361159  0.04366475  0.00855401]\n",
      " [-0.02162073 -0.32771304 -0.33964375 -0.327148    0.21161705  0.2173236\n",
      "   0.17759325 -0.24361159  0.04366475  0.00855401]\n",
      " [-0.02162073 -0.32771304 -0.33964375 -0.327148    0.21161705  0.2173236\n",
      "   0.17759325 -0.24361159  0.04366475  0.00855401]\n",
      " [-0.02162073 -0.32771304 -0.33964375 -0.327148    0.21161705  0.2173236\n",
      "   0.17759325 -0.24361159  0.04366475  0.00855401]\n",
      " [-0.02162073 -0.32771304 -0.33964375 -0.327148    0.21161705  0.2173236\n",
      "   0.17759325 -0.24361159  0.04366475  0.00855401]], shape=(6, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "length = 6\n",
    "d_wordemb = 3\n",
    "d_q = 10\n",
    "d_k, d_v = d_q, d_q\n",
    "input_attent = tf1.ones(dtype=tf.float32, shape=(batch_size, length, d_wordemb))\n",
    "print(self_attention(input_attent, length, d_wordemb, d_q, d_k, d_v))\n",
    "print(input_attent)\n",
    "print(self_attention(input_attent, length, d_wordemb, d_q, d_k, d_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e24e7b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 10]\n",
      "tf.Tensor(\n",
      "[[[ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]\n",
      "  [ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]\n",
      "  [ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]\n",
      "  [ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]\n",
      "  [ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]\n",
      "  [ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]]\n",
      "\n",
      " [[ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]\n",
      "  [ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]\n",
      "  [ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]\n",
      "  [ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]\n",
      "  [ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]\n",
      "  [ 0.0156476  -0.05705681 -0.02272506  0.07728692  0.22790529\n",
      "    0.1498493  -0.08732     0.14722544 -0.33117753  0.1204984 ]]], shape=(2, 6, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "length = 6\n",
    "d_wordemb = 3\n",
    "d_q = 10\n",
    "d_k, d_v = d_q, d_q\n",
    "input_attent = tf1.ones(dtype=tf.float32, shape=(batch_size, length, d_wordemb))\n",
    "with tf1.variable_scope(\"attention\", reuse=tf1.AUTO_REUSE):\n",
    "    Q = tf1.get_variable(\"Q\", shape=(d_wordemb, d_q), trainable = True, dtype=tf.float32)\n",
    "    K = tf1.get_variable(\"K\", shape=(d_wordemb, d_k), trainable = True, dtype=tf.float32)\n",
    "    V = tf1.get_variable(\"V\", shape=(d_wordemb, d_v), trainable = True, dtype=tf.float32)\n",
    "    Q_ = tf.matmul(input_attent, Q)\n",
    "    K_ = tf.matmul(input_attent, K)\n",
    "    V_ = tf.matmul(input_attent, V)\n",
    "    print(Q_.shape.as_list())\n",
    "    attent_score = tf1.math.softmax(tf.matmul(Q_, K_, transpose_b=True)) / tf.sqrt(tf.constant(d_k, dtype=tf.float32))\n",
    "    attent_out = tf.matmul(attent_score, V_)\n",
    "    print(attent_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d39ee006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Q:0' shape=(3, 10) dtype=float32, numpy=\n",
      "array([[ 0.19949502,  0.01219726,  0.5433166 , -0.06214291, -0.57688445,\n",
      "        -0.03760684,  0.5297984 , -0.0648542 , -0.14330155, -0.5094537 ],\n",
      "       [-0.32353047, -0.16308922, -0.43331045, -0.01969111, -0.10830683,\n",
      "         0.5743753 , -0.50289965, -0.28348333, -0.5819816 , -0.41693673],\n",
      "       [-0.01834399, -0.66433656,  0.30817652, -0.30229637,  0.32434022,\n",
      "         0.22467577,  0.11631721, -0.21327946,  0.6299032 ,  0.5993732 ]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "Q = tf1.get_variable(\"Q\", shape=(d_wordemb, d_q), trainable = True, dtype=tf.float32)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0551a415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Q:0' shape=(3, 10) dtype=float32, numpy=\n",
      "array([[ 0.49030828,  0.43385792,  0.32699132,  0.19241726, -0.29884312,\n",
      "        -0.49370098,  0.14936376, -0.22276059, -0.51242286,  0.66412425],\n",
      "       [-0.46666342,  0.47434616, -0.5589812 , -0.21409887,  0.5826361 ,\n",
      "        -0.22324648,  0.37553775,  0.65529764,  0.50622296,  0.62810814],\n",
      "       [ 0.09057331,  0.6159756 ,  0.21252304, -0.6021967 , -0.385796  ,\n",
      "         0.5926521 , -0.1164465 , -0.21251771,  0.52219963, -0.29116136]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "Q = tf1.get_variable(\"Q\", shape=(d_wordemb, d_q), trainable = True, dtype=tf.float32)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8e40938",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5cfd1e061e5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Creates v.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Creates v.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mv1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def foo(name, shape, reuse=None):\n",
    "    with tf1.variable_scope(\"foo\", shape, reuse=True) as scope:\n",
    "        if reuse:\n",
    "            val = tf1.get_variable(name, [1])\n",
    "        else:\n",
    "            val = tf1.get_variable(name, [1])\n",
    "       \n",
    "        return val\n",
    "\n",
    "v1 = foo(\"a\", [1])  # Creates v.\n",
    "v2 = foo(\"b\", [1], True)  # Creates v.\n",
    "assert v1 == v2\n",
    "print(tf1.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "629eeb64",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None has invalid type <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-fcf39fa13fa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Run the variable initializer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# ...you now can run ops that use the value of 'w'...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tfgpu_py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 968\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tfgpu_py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1174\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1176\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tfgpu_py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \"\"\"\n\u001b[0;32m    486\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tfgpu_py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' %\n\u001b[1;32m--> 265\u001b[1;33m                       (fetch, type(fetch)))\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument None has invalid type <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# Create a variable.\n",
    "\n",
    "w = tf1.Variable([0.1], shape=(1), name=\"x1\")\n",
    "init_op = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    \n",
    "    # Run the variable initializer.\n",
    "    sess.run(init_op)\n",
    "    # ...you now can run ops that use the value of 'w'...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29a59a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu_py36",
   "language": "python",
   "name": "tfgpu_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
